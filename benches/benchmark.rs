// Copyright (c) 2025 Kirky.X
//
// Licensed under the MIT License
// See LICENSE file in the project root for full license information.

//! æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶
//!
//! è¯¥æ¨¡å—åŒ…å«å¯¹ crawlrs ç³»ç»Ÿæ ¸å¿ƒç»„ä»¶çš„æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°ç³»ç»Ÿåœ¨ä¸åŒåœºæ™¯ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚

use crawlrs::domain::models::task::{Task, TaskType};
use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};
use migration::{Migrator, MigratorTrait};
use sea_orm::{
    ColumnTrait, Database, DatabaseConnection, DbErr, EntityTrait, PaginatorTrait, QueryFilter,
    QueryOrder, QuerySelect,
};
use std::hint::black_box;
use tokio::runtime::Runtime;
use uuid::Uuid;

/// åˆ›å»ºæµ‹è¯•æ•°æ®åº“è¿æ¥å¹¶è¿è¡Œè¿ç§»
async fn create_test_db() -> Result<DatabaseConnection, DbErr> {
    let db = Database::connect("sqlite::memory:").await?;

    // è¿è¡Œæ•°æ®åº“è¿ç§»
    Migrator::up(&db, None).await?;

    Ok(db)
}

/// åŸºå‡†æµ‹è¯•ï¼šä»»åŠ¡åˆ›å»ºæ€§èƒ½
///
/// æµ‹è¯•åœ¨ä¸åŒå¹¶å‘çº§åˆ«ä¸‹åˆ›å»ºä»»åŠ¡çš„æ€§èƒ½è¡¨ç°ï¼ŒåŒ…æ‹¬æ•°æ®åº“æŒä¹…åŒ–æ“ä½œ
fn benchmark_task_creation(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let db = rt
        .block_on(create_test_db())
        .expect("Failed to setup test database");

    let mut group = c.benchmark_group("task_creation");

    // æµ‹è¯•å†…å­˜ä¸­çš„ä»»åŠ¡åˆ›å»º
    for size in [10, 100, 1000].iter() {
        group.bench_with_input(
            BenchmarkId::new("memory_creation", size),
            size,
            |b, &size| {
                b.iter(|| {
                    let mut tasks = Vec::new();
                    for i in 0..size {
                        let task = Task::new(
                            TaskType::Scrape,
                            Uuid::new_v4(),
                            format!("https://example{}.com", i),
                            serde_json::json!({"test": true}),
                        );
                        tasks.push(task);
                    }
                    black_box(tasks)
                });
            },
        );
    }

    // æµ‹è¯•æ•°æ®åº“æŒä¹…åŒ–çš„ä»»åŠ¡åˆ›å»º
    for size in [10, 100, 500].iter() {
        group.bench_with_input(
            BenchmarkId::new("database_persistence", size),
            size,
            |b, &size| {
                b.iter(|| {
                    let rt = Runtime::new().unwrap();
                    let db = &db;
                    let mut tasks = Vec::new();

                    for i in 0..size {
                        let task = crawlrs::infrastructure::database::entities::task::ActiveModel {
                            id: sea_orm::Set(Uuid::new_v4()),
                            crawl_id: sea_orm::Set(None),
                            task_type: sea_orm::Set("scrape".to_string()),
                            status: sea_orm::Set("queued".to_string()),
                            priority: sea_orm::Set(0),
                            team_id: sea_orm::Set(Uuid::new_v4()),
                            url: sea_orm::Set(format!("https://example{}.com", i)),
                            payload: sea_orm::Set(serde_json::json!({"test": true})),
                            attempt_count: sea_orm::Set(0),
                            max_retries: sea_orm::Set(3),
                            created_at: sea_orm::Set(chrono::Utc::now().into()),
                            updated_at: sea_orm::Set(chrono::Utc::now().into()),
                            scheduled_at: sea_orm::Set(None),
                            started_at: sea_orm::Set(None),
                            completed_at: sea_orm::Set(None),
                            lock_token: sea_orm::Set(None),
                            lock_expires_at: sea_orm::Set(None),
                            expires_at: sea_orm::Set(None),
                        };
                        tasks.push(task);
                    }

                    // æ‰¹é‡æ’å…¥åˆ°æ•°æ®åº“
                    let result = rt.block_on(async {
                        crawlrs::infrastructure::database::entities::task::Entity::insert_many(
                            tasks,
                        )
                        .exec(db)
                        .await
                    });

                    black_box(result)
                });
            },
        );
    }

    group.finish();
}

/// åŸºå‡†æµ‹è¯•ï¼šä»»åŠ¡çŠ¶æ€è½¬æ¢
///
/// æµ‹è¯•ä»»åŠ¡åœ¨ä¸åŒçŠ¶æ€ä¹‹é—´è½¬æ¢çš„æ€§èƒ½
fn benchmark_task_status_transitions(c: &mut Criterion) {
    let _rt = Runtime::new().unwrap();

    let mut group = c.benchmark_group("task_status_transitions");

    // æµ‹è¯•å•ä¸ªä»»åŠ¡çš„çŠ¶æ€è½¬æ¢
    group.bench_function("single_task_lifecycle", |b| {
        b.iter(|| {
            let mut task = Task::new(
                TaskType::Scrape,
                Uuid::new_v4(),
                "https://example.com".to_string(),
                serde_json::json!({}),
            );

            // æ¨¡æ‹Ÿå®Œæ•´çš„ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸ
            task = task.start().unwrap();
            task = task.complete().unwrap();

            black_box(task)
        });
    });

    // æµ‹è¯•æ‰¹é‡ä»»åŠ¡çŠ¶æ€è½¬æ¢
    for batch_size in [10, 50, 100].iter() {
        group.bench_with_input(
            BenchmarkId::from_parameter(batch_size),
            batch_size,
            |b, &batch_size| {
                b.iter(|| {
                    let mut tasks = Vec::new();
                    for i in 0..batch_size {
                        let mut task = Task::new(
                            TaskType::Scrape,
                            Uuid::new_v4(),
                            format!("https://example{}.com", i),
                            serde_json::json!({}),
                        );
                        task = task.start().unwrap();
                        tasks.push(task);
                    }
                    black_box(tasks)
                });
            },
        );
    }

    group.finish();
}

/// åŸºå‡†æµ‹è¯•ï¼šJSONåºåˆ—åŒ–/ååºåˆ—åŒ–
///
/// æµ‹è¯•ä»»åŠ¡å¯¹è±¡çš„JSONåºåˆ—åŒ–å’Œååºåˆ—åŒ–æ€§èƒ½
fn benchmark_json_serialization(c: &mut Criterion) {
    let _rt = Runtime::new().unwrap();

    let mut group = c.benchmark_group("json_serialization");

    // åˆ›å»ºæµ‹è¯•ä»»åŠ¡
    let task = Task::new(
        TaskType::Scrape,
        Uuid::new_v4(),
        "https://example.com".to_string(),
        serde_json::json!({
            "complex": {
                "nested": {
                    "data": "test content with special characters: ä½ å¥½ä¸–ç•Œ ğŸŒ"
                }
            },
            "array": [1, 2, 3, 4, 5],
            "boolean": true,
            "number": 42.5
        }),
    );

    // åºåˆ—åŒ–åŸºå‡†æµ‹è¯•
    group.bench_function("serialize_task", |b| {
        b.iter(|| {
            let json_str = serde_json::to_string(&task).unwrap();
            black_box(json_str)
        });
    });

    // ååºåˆ—åŒ–åŸºå‡†æµ‹è¯•
    let task_json = serde_json::to_string(&task).unwrap();
    group.bench_function("deserialize_task", |b| {
        b.iter(|| {
            let deserialized: Task = serde_json::from_str(&task_json).unwrap();
            black_box(deserialized)
        });
    });

    // æµ‹è¯•ä¸åŒå¤§å°çš„payload
    for payload_size in ["small", "medium", "large"].iter() {
        let payload = match *payload_size {
            "small" => serde_json::json!({"key": "value"}),
            "medium" => serde_json::json!({
                "title": "Test Page",
                "content": "This is a medium-sized content with some text and numbers: 12345",
                "metadata": {
                    "author": "Test Author",
                    "date": "2024-01-01",
                    "tags": ["test", "benchmark", "performance"]
                }
            }),
            "large" => serde_json::json!({
                "page_content": "A".repeat(10000),  // 10KB of content
                "nested_structures": {
                    "level1": {
                        "level2": {
                            "level3": {
                                "data": (0..100).collect::<Vec<i32>>(),
                                "text": "Deep nested content with unicode: ä½ å¥½ä¸–ç•Œ ğŸŒ ğŸ‰"
                            }
                        }
                    }
                },
                "arrays": (0..1000).map(|i| format!("item_{}", i)).collect::<Vec<String>>(),
                "mixed_types": {
                    "string": "text",
                    "number": 42.5,
                    "boolean": true,
                    "null": null,
                    "array": [1, 2, 3],
                    "object": {"nested": "value"}
                }
            }),
            _ => serde_json::json!({}),
        };

        group.bench_with_input(
            BenchmarkId::new("serialize_payload", payload_size),
            &payload,
            |b, payload| {
                b.iter(|| {
                    let json_str = serde_json::to_string(payload).unwrap();
                    black_box(json_str)
                });
            },
        );
    }

    group.finish();
}

/// åŸºå‡†æµ‹è¯•ï¼šUUIDç”Ÿæˆå’Œå¤„ç†
///
/// æµ‹è¯•UUIDç”Ÿæˆå’Œå­—ç¬¦ä¸²è½¬æ¢çš„æ€§èƒ½
fn benchmark_uuid_operations(c: &mut Criterion) {
    let mut group = c.benchmark_group("uuid_operations");

    // UUIDç”Ÿæˆ
    group.bench_function("generate_uuid_v4", |b| {
        b.iter(|| {
            let id = Uuid::new_v4();
            black_box(id)
        });
    });

    // UUIDåˆ°å­—ç¬¦ä¸²è½¬æ¢
    group.bench_function("uuid_to_string", |b| {
        let id = Uuid::new_v4();
        b.iter(|| {
            let s = id.to_string();
            black_box(s)
        });
    });

    // å­—ç¬¦ä¸²åˆ°UUIDè½¬æ¢
    let uuid_str = Uuid::new_v4().to_string();
    group.bench_function("string_to_uuid", |b| {
        b.iter(|| {
            let id = Uuid::parse_str(&uuid_str).unwrap();
            black_box(id)
        });
    });

    group.finish();
}

/// åŸºå‡†æµ‹è¯•ï¼šå†…å­˜åˆ†é…å’Œå…‹éš†æ“ä½œ
///
/// æµ‹è¯•ä»»åŠ¡å¯¹è±¡çš„å†…å­˜åˆ†é…å’Œå…‹éš†æ€§èƒ½
fn benchmark_memory_operations(c: &mut Criterion) {
    let mut group = c.benchmark_group("memory_operations");

    // åˆ›å»ºåŒ…å«å¤§é‡æ•°æ®çš„ä»»åŠ¡
    let task = Task::new(
        TaskType::Scrape,
        Uuid::new_v4(),
        "https://example.com/very/long/url/path/with/many/segments/and/query/parameters?param1=value1&param2=value2&param3=value3".to_string(),
        serde_json::json!({
            "large_content": "A".repeat(100000),  // 100KB
            "nested_data": {
                "repeated_section": (0..1000).map(|i| {
                    serde_json::json!({
                        "id": i,
                        "name": format!("item_{}", i),
                        "description": format!("This is a description for item {}", i),
                        "metadata": {
                            "created": "2024-01-01T00:00:00Z",
                            "updated": "2024-01-01T12:00:00Z",
                            "tags": ["tag1", "tag2", "tag3"]
                        }
                    })
                }).collect::<Vec<_>>()
            }
        })
    );

    // å…‹éš†æ“ä½œ
    group.bench_function("clone_large_task", |b| {
        b.iter(|| {
            let cloned = task.clone();
            black_box(cloned)
        });
    });

    // å†…å­˜åˆ†é…æµ‹è¯• - åˆ›å»ºå¤šä¸ªä»»åŠ¡
    group.bench_function("allocate_task_batch", |b| {
        b.iter(|| {
            let tasks: Vec<Task> = (0..100)
                .map(|i| {
                    Task::new(
                        TaskType::Scrape,
                        Uuid::new_v4(),
                        format!("https://example{}.com", i),
                        serde_json::json!({"index": i}),
                    )
                })
                .collect();
            black_box(tasks)
        });
    });

    group.finish();
}

/// åŸºå‡†æµ‹è¯•ï¼šå¹¶å‘ä»»åŠ¡å¤„ç†
///
/// æµ‹è¯•ç³»ç»Ÿåœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹çš„ä»»åŠ¡å¤„ç†æ€§èƒ½
fn benchmark_concurrent_task_processing(c: &mut Criterion) {
    let _rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("concurrent_task_processing");

    // æµ‹è¯•ä¸åŒå¹¶å‘çº§åˆ«çš„ä»»åŠ¡åˆ›å»º
    for concurrency in [10, 50, 100].iter() {
        group.bench_with_input(
            BenchmarkId::new("create_concurrent_tasks", concurrency),
            concurrency,
            |b, &concurrency| {
                b.iter(|| {
                    let mut tasks = Vec::new();
                    for i in 0..concurrency {
                        let task = Task::new(
                            TaskType::Scrape,
                            Uuid::new_v4(),
                            format!("https://example{}.com", i),
                            serde_json::json!({"task_id": i}),
                        );
                        tasks.push(task);
                    }
                    black_box(tasks)
                });
            },
        );
    }

    group.finish();
}

/// åŸºå‡†æµ‹è¯•ï¼šé”™è¯¯å¤„ç†æ€§èƒ½
///
/// æµ‹è¯•ç³»ç»Ÿåœ¨å¤„ç†é”™è¯¯æƒ…å†µæ—¶çš„æ€§èƒ½è¡¨ç°
fn benchmark_error_handling(c: &mut Criterion) {
    let mut group = c.benchmark_group("error_handling");

    // æµ‹è¯•ä»»åŠ¡çŠ¶æ€è½¬æ¢ä¸­çš„é”™è¯¯å¤„ç†
    group.bench_function("task_state_validation", |b| {
        let completed_task = Task::new(
            TaskType::Scrape,
            Uuid::new_v4(),
            "https://example.com".to_string(),
            serde_json::json!({}),
        );
        let completed_task = completed_task.complete().unwrap();

        b.iter(|| {
            // å°è¯•å¯¹å·²å®Œæˆçš„ä»»åŠ¡æ‰§è¡Œæ— æ•ˆæ“ä½œ
            let result = completed_task.clone().start();
            black_box(result)
        });
    });

    // JSONè§£æé”™è¯¯å¤„ç†
    let invalid_json = r#"{"invalid": json}"#;
    group.bench_function("json_parse_error", |b| {
        b.iter(|| {
            let result: Result<Task, _> = serde_json::from_str(invalid_json);
            black_box(result)
        });
    });

    // UUIDè§£æé”™è¯¯å¤„ç†
    let invalid_uuid = "not-a-valid-uuid";
    group.bench_function("uuid_parse_error", |b| {
        b.iter(|| {
            let result = Uuid::parse_str(invalid_uuid);
            black_box(result)
        });
    });

    group.finish();
}

/// åŸºå‡†æµ‹è¯•ï¼šæ•°æ®åº“æŸ¥è¯¢æ“ä½œ
///
/// æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ï¼ŒåŒ…æ‹¬ç´¢å¼•ä½¿ç”¨å’Œå¤æ‚æŸ¥è¯¢
fn benchmark_database_queries(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let db = rt
        .block_on(create_test_db())
        .expect("Failed to setup test database");

    // é¢„å¡«å……æµ‹è¯•æ•°æ®
    rt.block_on(async {
        let mut tasks = Vec::new();
        for i in 0..1000 {
            let task = crawlrs::infrastructure::database::entities::task::ActiveModel {
                id: sea_orm::Set(Uuid::new_v4()),
                crawl_id: sea_orm::Set(None),
                task_type: sea_orm::Set(if i % 3 == 0 {
                    "scrape".to_string()
                } else if i % 3 == 1 {
                    "crawl".to_string()
                } else {
                    "extract".to_string()
                }),
                status: sea_orm::Set(if i % 4 == 0 {
                    "completed".to_string()
                } else if i % 4 == 1 {
                    "failed".to_string()
                } else if i % 4 == 2 {
                    "active".to_string()
                } else {
                    "queued".to_string()
                }),
                priority: sea_orm::Set((i % 5) as i32),
                team_id: sea_orm::Set(Uuid::new_v4()),
                url: sea_orm::Set(format!("https://example{}.com", i)),
                payload: sea_orm::Set(serde_json::json!({"test": true, "index": i})),
                attempt_count: sea_orm::Set(0),
                max_retries: sea_orm::Set(3),
                created_at: sea_orm::Set(chrono::Utc::now().into()),
                updated_at: sea_orm::Set(chrono::Utc::now().into()),
                scheduled_at: sea_orm::Set(None),
                started_at: sea_orm::Set(None),
                completed_at: sea_orm::Set(None),
                lock_token: sea_orm::Set(None),
                lock_expires_at: sea_orm::Set(None),
                expires_at: sea_orm::Set(None),
            };
            tasks.push(task);
        }

        crawlrs::infrastructure::database::entities::task::Entity::insert_many(tasks)
            .exec(&db)
            .await
            .expect("Failed to insert test data");
    });

    let mut group = c.benchmark_group("database_queries");

    // åŸºç¡€æŸ¥è¯¢ - æŒ‰IDæŸ¥è¯¢
    group.bench_function("query_by_id", |b| {
        b.iter(|| {
            let rt = Runtime::new().unwrap();
            let task_id = Uuid::new_v4();
            let result = rt.block_on(async {
                crawlrs::infrastructure::database::entities::task::Entity::find_by_id(task_id)
                    .one(&db)
                    .await
            });
            black_box(result)
        });
    });

    // ç´¢å¼•æŸ¥è¯¢ - æŒ‰çŠ¶æ€æŸ¥è¯¢
    group.bench_function("query_by_status", |b| {
        b.iter(|| {
            let rt = Runtime::new().unwrap();
            let result = rt.block_on(async {
                crawlrs::infrastructure::database::entities::task::Entity::find()
                    .filter(
                        crawlrs::infrastructure::database::entities::task::Column::Status
                            .eq("queued"),
                    )
                    .limit(10)
                    .all(&db)
                    .await
            });
            black_box(result)
        });
    });

    // å¤åˆç´¢å¼•æŸ¥è¯¢ - æŒ‰çŠ¶æ€å’Œä¼˜å…ˆçº§æ’åº
    group.bench_function("query_by_status_priority", |b| {
        b.iter(|| {
            let rt = Runtime::new().unwrap();
            let result = rt.block_on(async {
                crawlrs::infrastructure::database::entities::task::Entity::find()
                    .filter(
                        crawlrs::infrastructure::database::entities::task::Column::Status
                            .eq("queued"),
                    )
                    .order_by_asc(
                        crawlrs::infrastructure::database::entities::task::Column::Priority,
                    )
                    .order_by_asc(
                        crawlrs::infrastructure::database::entities::task::Column::CreatedAt,
                    )
                    .limit(10)
                    .all(&db)
                    .await
            });
            black_box(result)
        });
    });

    // èšåˆæŸ¥è¯¢ - ç»Ÿè®¡ä»»åŠ¡æ•°é‡
    group.bench_function("count_tasks", |b| {
        b.iter(|| {
            let rt = Runtime::new().unwrap();
            let result = rt.block_on(async {
                crawlrs::infrastructure::database::entities::task::Entity::find()
                    .filter(
                        crawlrs::infrastructure::database::entities::task::Column::Status
                            .eq("completed"),
                    )
                    .count(&db)
                    .await
            });
            black_box(result)
        });
    });

    group.finish();
}

/// åŸºå‡†æµ‹è¯•ï¼šå­—ç¬¦ä¸²æ“ä½œ
///
/// æµ‹è¯•å¸¸ç”¨çš„å­—ç¬¦ä¸²æ“ä½œæ€§èƒ½
fn benchmark_string_operations(c: &mut Criterion) {
    let mut group = c.benchmark_group("string_operations");

    // URLéªŒè¯å’Œå¤„ç†
    let test_urls = vec![
        "https://example.com",
        "https://subdomain.example.com/path/to/resource?param=value&other=123",
        "http://localhost:8080/api/v1/endpoint",
        "https://example.com/very/long/path/with/many/segments/and/query/parameters?param1=value1&param2=value2&param3=value3",
    ];

    group.bench_function("url_validation", |b| {
        b.iter(|| {
            for url in &test_urls {
                let is_valid = url.starts_with("http://") || url.starts_with("https://");
                black_box(is_valid);
            }
        });
    });

    // JSONå­—ç¬¦ä¸²è½¬ä¹‰
    let test_content = r#"Content with "quotes" and special chars: 
	
 and unicode: ä½ å¥½ä¸–ç•Œ ğŸŒ"#;

    group.bench_function("json_string_escape", |b| {
        b.iter(|| {
            let escaped = serde_json::to_string(test_content).unwrap();
            black_box(escaped)
        });
    });

    // å­—ç¬¦ä¸²æˆªæ–­æ“ä½œ
    let long_content = "A".repeat(10000);
    group.bench_function("string_truncation", |b| {
        b.iter(|| {
            let truncated = if long_content.len() > 1000 {
                format!("{}...", &long_content[..1000])
            } else {
                long_content.clone()
            };
            black_box(truncated)
        });
    });

    group.finish();
}

// åŸºå‡†æµ‹è¯•ç»„åˆ
criterion_group!(
    benches,
    benchmark_task_creation,
    benchmark_task_status_transitions,
    benchmark_json_serialization,
    benchmark_uuid_operations,
    benchmark_memory_operations,
    benchmark_concurrent_task_processing,
    benchmark_error_handling,
    benchmark_database_queries,
    benchmark_string_operations
);

criterion_main!(benches);
