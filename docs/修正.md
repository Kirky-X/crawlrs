# crawlrs å¼‚æ­¥æ¥å£ä¼˜åŒ– - æ–‡æ¡£ä¿®æ­£æŒ‡å—

## ç‰ˆæœ¬ä¿¡æ¯
- **æ–‡æ¡£ç‰ˆæœ¬**: v2.1.0
- **å˜æ›´ç±»å‹**: åŠŸèƒ½å¢å¼ºï¼ˆå¼‚æ­¥æ¥å£åŒæ­¥ç­‰å¾…ä¼˜åŒ–ï¼‰
- **å˜æ›´æ—¥æœŸ**: 2024-12-18
- **å½±å“èŒƒå›´**: PRD, TDD, TASK, TEST, UAT

---

## å˜æ›´æ¦‚è¿°

### æ ¸å¿ƒå˜æ›´
ä¸ºæ”¹å–„ç”¨æˆ·ä½“éªŒï¼Œåœ¨å¼‚æ­¥æ¥å£ä¸­å¼•å…¥ **å¯é…ç½®çš„åŒæ­¥ç­‰å¾…æœºåˆ¶**ï¼Œå…è®¸å®¢æˆ·ç«¯é€‰æ‹©ï¼š
1. **ç«‹å³è¿”å›ä»»åŠ¡ID**ï¼ˆåŸè¡Œä¸ºï¼Œé€‚ç”¨äºé•¿ä»»åŠ¡ï¼‰
2. **ç­‰å¾…ä»»åŠ¡å®Œæˆåè¿”å›ç»“æœ**ï¼ˆæ–°å¢ï¼Œé€‚ç”¨äºå¿«é€Ÿä»»åŠ¡ï¼‰

### è®¾è®¡åŸåˆ™
- **å‘åå…¼å®¹**ï¼šé»˜è®¤è¡Œä¸ºä¿æŒä¸å˜ï¼ˆç«‹å³è¿”å›ä»»åŠ¡IDï¼‰
- **å¯é…ç½®**ï¼šå®¢æˆ·ç«¯é€šè¿‡å‚æ•°æ§åˆ¶ç­‰å¾…è¡Œä¸º
- **æ€§èƒ½å¯æ§**ï¼šé™åˆ¶æœ€å¤§ç­‰å¾…æ—¶é—´å’Œå¹¶å‘ç­‰å¾…æ•°
- **åˆ†ç±»ç®¡ç†**ï¼šä¸åŒä»»åŠ¡ç±»å‹æœ‰ä¸åŒçš„ç­‰å¾…é…ç½®

---

## 1. PRD.md ä¿®æ­£æ¸…å•

### 1.1 ã€ç¬¬ 3 èŠ‚ - æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ã€‘ä¿®æ­£

#### ä¿®æ­£ä½ç½®ï¼š3.1 æœç´¢ (Search)

**åŸæ–‡**:
```json
{
  "success": true,
  "data": {
    "web": [...]
  },
  "scrape_ids": ["uuid-1", "uuid-2"],
  "credits_used": 15
}
```

**ä¿®æ­£ä¸º**:
```markdown
### 3.1 æœç´¢ (Search)

**è¾“å…¥å‚æ•°**ï¼ˆæ–°å¢ï¼‰:
- `query`: æœç´¢å…³é”®è¯ï¼ˆå¿…å¡«ï¼‰
- `sources`: æ¥æºç±»å‹ï¼ˆweb/news/imagesï¼Œé»˜è®¤ webï¼‰
- `limit`: ç»“æœæ•°é‡ï¼ˆ1-100ï¼Œé»˜è®¤ 10ï¼‰
- `scrape_options`: æŠ“å–é…ç½®ï¼ˆå¯é€‰ï¼‰
- `async_scraping`: æ˜¯å¦å¼‚æ­¥æŠ“å–ï¼ˆé»˜è®¤ falseï¼‰
- **`wait_for_completion`**: æ˜¯å¦ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆé»˜è®¤ falseï¼‰âœ¨ æ–°å¢
- **`wait_timeout_ms`**: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼Œé»˜è®¤ 2000ï¼Œæœ€å¤§ 5000ï¼‰âœ¨ æ–°å¢

**è¾“å‡ºå“åº”**:

**åœºæ™¯ 1: åŒæ­¥ç­‰å¾…æ¨¡å¼ï¼ˆwait_for_completion=true ä¸”ä»»åŠ¡åœ¨è¶…æ—¶å‰å®Œæˆï¼‰**
```json
{
  "success": true,
  "mode": "immediate",
  "data": {
    "web": [
      {
        "title": "Example Title",
        "url": "https://example.com",
        "description": "...",
        "content": "å®Œæ•´çš„é¡µé¢å†…å®¹..."
      }
    ]
  },
  "credits_used": 15,
  "response_time_ms": 1234
}
```

**åœºæ™¯ 2: å¼‚æ­¥æ¨¡å¼ï¼ˆwait_for_completion=false æˆ–ç­‰å¾…è¶…æ—¶ï¼‰**
```json
{
  "success": true,
  "mode": "async",
  "scrape_ids": ["uuid-1", "uuid-2"],
  "status_url": "/v1/scrape/batch?ids=uuid-1,uuid-2",
  "estimated_completion_sec": 10,
  "credits_reserved": 15
}
```

**ä¸šåŠ¡è§„åˆ™**ï¼ˆæ–°å¢ç¬¬ 4 æ¡ï¼‰:
1. æ¯ä¸ªæœç´¢è¯·æ±‚æ¶ˆè€— **1 Credit**
2. æ¯ä¸ªå›å¡«æŠ“å–é¢å¤–æ¶ˆè€— **1-5 Credits**ï¼ˆè§†å†…å®¹å¤æ‚åº¦ï¼‰
3. å¼‚æ­¥æ¨¡å¼ä¸‹ç«‹å³è¿”å›ä»»åŠ¡ IDï¼Œç»“æœé€šè¿‡ Webhook å›è°ƒ
4. **åŒæ­¥ç­‰å¾…æ¨¡å¼ä¸‹ï¼Œè‹¥è¶…æ—¶åˆ™è‡ªåŠ¨é™çº§ä¸ºå¼‚æ­¥æ¨¡å¼ï¼Œä¸é¢å¤–æ‰£è´¹** âœ¨ æ–°å¢
```

---

#### ä¿®æ­£ä½ç½®ï¼š3.2 æŠ“å– (Scrape)

**åœ¨ "è¾“å…¥å‚æ•° - options" ä¸‹æ–°å¢**:
```markdown
- `options`: 
  - `headers`: è‡ªå®šä¹‰ HTTP å¤´
  - `timeout`: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤ 30ï¼‰
  - `mobile`: æ˜¯å¦æ¨¡æ‹Ÿç§»åŠ¨ç«¯ï¼ˆé»˜è®¤ falseï¼‰
  - `proxy`: ä»£ç†é…ç½®ï¼ˆå¯é€‰ï¼‰
  - `skip_tls_verification`: è·³è¿‡ TLS æ ¡éªŒï¼ˆé»˜è®¤ falseï¼‰
  - **`wait_for_completion`**: æ˜¯å¦ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆé»˜è®¤ falseï¼‰âœ¨ æ–°å¢
  - **`wait_timeout_ms`**: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼Œé»˜è®¤ 3000ï¼Œæœ€å¤§ 10000ï¼‰âœ¨ æ–°å¢
```

**ä¿®æ­£è¾“å‡ºå“åº”**:
```markdown
**è¾“å‡ºå“åº”**:

**åœºæ™¯ 1: åŒæ­¥æ¨¡å¼ï¼ˆä»»åŠ¡å¿«é€Ÿå®Œæˆï¼‰**
```json
{
  "success": true,
  "mode": "immediate",
  "data": {
    "markdown": "# Page Title\n...",
    "html": "<html>...",
    "metadata": {
      "title": "Page Title",
      "description": "...",
      "status_code": 200,
      "content_type": "text/html",
      "response_time_ms": 234
    }
  },
  "credits_used": 3
}
```

**åœºæ™¯ 2: å¼‚æ­¥æ¨¡å¼ï¼ˆä»»åŠ¡æ’é˜Ÿæˆ–è¶…æ—¶ï¼‰**
```json
{
  "success": true,
  "mode": "async",
  "id": "task-uuid",
  "status": "processing",
  "status_url": "/v1/scrape/task-uuid",
  "estimated_completion_sec": 5,
  "credits_reserved": 3
}
```
```

---

#### ä¿®æ­£ä½ç½®ï¼š3.4 æå– (Extract)

**åœ¨è¾“å…¥å‚æ•°ä¸‹æ–°å¢**:
```markdown
- `options`:
  - `agent`: LLM æ¨¡å‹ï¼ˆgpt-4/claude-3/gemini-proï¼‰
  - `enable_web_search`: æ˜¯å¦å…è®¸è”ç½‘æœç´¢
  - `max_concurrency`: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤ 5ï¼‰
  - **`wait_for_completion`**: æ˜¯å¦ç­‰å¾…æå–å®Œæˆï¼ˆé»˜è®¤ falseï¼‰âœ¨ æ–°å¢
  - **`wait_timeout_ms`**: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼Œé»˜è®¤ 5000ï¼Œæœ€å¤§ 15000ï¼‰âœ¨ æ–°å¢
```

---

### 1.2 ã€æ–°å¢ç¬¬ 3.6 èŠ‚ - å¼‚æ­¥ç­‰å¾…æœºåˆ¶ã€‘

```markdown
### 3.6 å¼‚æ­¥ç­‰å¾…æœºåˆ¶ âœ¨ æ–°å¢

**åŠŸèƒ½æè¿°**: ä¸ºæ”¹å–„ç”¨æˆ·ä½“éªŒï¼Œç³»ç»Ÿæ”¯æŒåœ¨å¼‚æ­¥æ¥å£ä¸­è¿›è¡Œæœ‰é™æ—¶é—´çš„åŒæ­¥ç­‰å¾…ã€‚

#### 3.6.1 è®¾è®¡åŸåˆ™

1. **å¯é…ç½®æ€§**: å®¢æˆ·ç«¯é€šè¿‡ `wait_for_completion` å’Œ `wait_timeout_ms` å‚æ•°æ§åˆ¶è¡Œä¸º
2. **æ€§èƒ½ä¿æŠ¤**: ç³»ç»Ÿé™åˆ¶æœ€å¤§ç­‰å¾…æ—¶é—´å’Œå¹¶å‘ç­‰å¾…æ•°é‡
3. **é™çº§ç­–ç•¥**: è¶…æ—¶åè‡ªåŠ¨é™çº§ä¸ºæ ‡å‡†å¼‚æ­¥æ¨¡å¼
4. **èµ„æºéš”ç¦»**: ç­‰å¾…è¯·æ±‚ä½¿ç”¨ç‹¬ç«‹çš„ä¿¡å·é‡æ± ï¼Œä¸å½±å“æ­£å¸¸è¯·æ±‚

#### 3.6.2 ç­‰å¾…æ—¶é—´é…ç½®

| ä»»åŠ¡ç±»å‹ | é»˜è®¤ç­‰å¾…æ—¶é—´ | æœ€å¤§ç­‰å¾…æ—¶é—´ | åŸå›  |
|---------|------------|------------|------|
| **Search** | 2000ms | 5000ms | æœç´¢ API å“åº”å¿« |
| **Scrape** | 3000ms | 10000ms | å¤§å¤šæ•°é¡µé¢ < 3s |
| **Extract** | 5000ms | 15000ms | LLM å¤„ç†éœ€è¦æ—¶é—´ |
| **Crawl** | N/A | N/A | å¿…é¡»å¼‚æ­¥ï¼ˆå¯èƒ½æ•°å°æ—¶ï¼‰ |

#### 3.6.3 å®ç°æœºåˆ¶

**æŠ€æœ¯æ¶æ„**:
```
Client Request (wait_for_completion=true)
    â†“
API Layer: åˆ›å»ºä»»åŠ¡ â†’ è·å– task_id
    â†“
Wait Manager: æ³¨å†Œç­‰å¾…ç›‘å¬å™¨
    â†“
Worker Pool: æ‰§è¡Œä»»åŠ¡
    â†“
    â”œâ”€ å®Œæˆ â†’ é€šçŸ¥ Wait Manager â†’ ç«‹å³è¿”å›ç»“æœ âœ…
    â”œâ”€ è¶…æ—¶ â†’ è¿”å›ä»»åŠ¡IDï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰ â±ï¸
    â””â”€ å¤±è´¥ â†’ ç«‹å³è¿”å›é”™è¯¯ âŒ
```

**å¹¶å‘æ§åˆ¶**:
- **æœ€å¤§å¹¶å‘ç­‰å¾…æ•°**: 500ï¼ˆé€šè¿‡ä¿¡å·é‡æ§åˆ¶ï¼‰
- **è¶…å‡ºé™åˆ¶è¡Œä¸º**: ç›´æ¥è¿”å›å¼‚æ­¥å“åº”ï¼Œä¸è¿›å…¥ç­‰å¾…é˜Ÿåˆ—
- **ç›‘æ§æŒ‡æ ‡**: `crawlrs_wait_queue_depth`

#### 3.6.4 å®¢æˆ·ç«¯æœ€ä½³å®è·µ

**æ¨èé…ç½®**:
```javascript
// å¿«é€Ÿä»»åŠ¡ï¼ˆå¦‚æŠ“å–æ–°é—»ç«™ç‚¹ï¼‰
{
  "url": "https://news.example.com",
  "wait_for_completion": true,
  "wait_timeout_ms": 3000
}

// å¤æ‚ä»»åŠ¡ï¼ˆå¦‚ SPA åº”ç”¨ï¼‰
{
  "url": "https://complex-spa.com",
  "wait_for_completion": false  // ç›´æ¥å¼‚æ­¥
}
```

**å®¢æˆ·ç«¯è¶…æ—¶è®¾ç½®**:
- HTTP Client Timeout åº”è®¾ä¸º `wait_timeout_ms + 2000ms`
- ç¤ºä¾‹ï¼š`wait_timeout_ms=5000` â†’ HTTP Timeout=7000ms

#### 3.6.5 è´¹ç”¨è¯´æ˜

- **æˆåŠŸç­‰å¾…**: æŒ‰å®é™…æ¶ˆè€—çš„ Credits è®¡è´¹
- **ç­‰å¾…è¶…æ—¶**: ä¸é¢å¤–æ”¶è´¹ï¼Œä»»åŠ¡ç»§ç»­æ‰§è¡Œï¼Œç»“æœé€šè¿‡ Webhook æˆ–è½®è¯¢è·å–
- **ç­‰å¾…å¤±è´¥**: å¦‚æœä»»åŠ¡æœ¬èº«å¤±è´¥ï¼Œä¸æ‰£é™¤ Credits
```

---

### 1.3 ã€ç¬¬ 8 èŠ‚ - æ€§èƒ½æŒ‡æ ‡ã€‘ä¿®æ­£

**åœ¨ 8.1 ç›®æ ‡æŒ‡æ ‡è¡¨æ ¼ä¸­æ–°å¢**:
```markdown
| æŒ‡æ ‡ | ç›®æ ‡å€¼ | æµ‹é‡æ–¹å¼ |
|------|--------|----------|
| **API ååé‡** | 10000 RPS | å‹åŠ›æµ‹è¯• |
| **P50 å»¶è¿Ÿï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰** | < 50ms | Prometheus |
| **P99 å»¶è¿Ÿï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰** | < 200ms | Prometheus |
| **P95 å»¶è¿Ÿï¼ˆåŒæ­¥ç­‰å¾…æ¨¡å¼ï¼‰** | < 5000ms | Prometheus | âœ¨ æ–°å¢
| **ç«‹å³å“åº”ç‡ï¼ˆåŒæ­¥æ¨¡å¼ï¼‰** | > 80% | ä¸šåŠ¡æŒ‡æ ‡ | âœ¨ æ–°å¢
| **ç­‰å¾…è¶…æ—¶ç‡** | < 15% | ä¸šåŠ¡æŒ‡æ ‡ | âœ¨ æ–°å¢
| **ä»»åŠ¡å¤„ç†é€Ÿåº¦** | 1000 tasks/min | Worker æŒ‡æ ‡ |
| **æˆåŠŸç‡** | > 99.9% | é”™è¯¯ç‡ç»Ÿè®¡ |
| **å¯ç”¨æ€§** | 99.95% | Uptime ç›‘æ§ |
```

---

### 1.4 ã€ç¬¬ 10 èŠ‚ - ç›‘æ§ä¸å‘Šè­¦ã€‘ä¿®æ­£

**åœ¨ 10.1 å…³é”®æŒ‡æ ‡ä¸‹æ–°å¢**:
```markdown
### 10.1 å…³é”®æŒ‡æ ‡

- **ä¸šåŠ¡æŒ‡æ ‡**: 
  - ä»»åŠ¡æˆåŠŸç‡
  - å¹³å‡å¤„ç†æ—¶é—´
  - Credits æ¶ˆè€—é€Ÿç‡
  - **ç«‹å³å“åº”ç‡ï¼ˆåŒæ­¥æ¨¡å¼ï¼‰** âœ¨ æ–°å¢
  - **å¹³å‡ç­‰å¾…æ—¶é—´** âœ¨ æ–°å¢
  - **ç­‰å¾…è¶…æ—¶æ¬¡æ•°** âœ¨ æ–°å¢
- **ç³»ç»ŸæŒ‡æ ‡**: 
  - CPU/å†…å­˜ä½¿ç”¨ç‡
  - æ•°æ®åº“è¿æ¥æ•°
  - é˜Ÿåˆ—ç§¯å‹æ•°é‡
  - **ç­‰å¾…é˜Ÿåˆ—æ·±åº¦** âœ¨ æ–°å¢
  - **å¹¶å‘ç­‰å¾…çº¿ç¨‹æ•°** âœ¨ æ–°å¢
```

---

## 2. TDD.md ä¿®æ­£æ¸…å•

### 2.1 ã€ç¬¬ 3.2 èŠ‚ - åº”ç”¨å±‚ã€‘æ–°å¢ç”¨ä¾‹

**åœ¨ "3.2 åº”ç”¨å±‚ (Application Layer)" ä¸‹æ–°å¢**:

```markdown
#### 3.2.2 ç”¨ä¾‹ç¤ºä¾‹ï¼šåŒæ­¥ç­‰å¾…æŠ“å–

**çŠ¶æ€**: ğŸš§ å¾…å®ç°

```rust
// application/usecases/create_scrape_with_wait.rs
use crate::domain::repositories::TaskRepository;
use crate::application::dto::{ScrapeRequest, ScrapeResponse};
use crate::workers::wait_manager::WaitManager;

pub struct CreateScrapeWithWaitUseCase<R: TaskRepository> {
    task_repo: Arc<R>,
    scrape_service: Arc<ScrapeService>,
    wait_manager: Arc<WaitManager>,
    config: AsyncWaitConfig,
}

impl<R: TaskRepository> CreateScrapeWithWaitUseCase<R> {
    pub async fn execute(
        &self,
        request: ScrapeRequest,
    ) -> Result<ScrapeResponse, UseCaseError> {
        // 1. åˆ›å»ºä»»åŠ¡
        let task = self.scrape_service.create_task(&request).await?;
        let task_id = task.id;
        
        // 2. åˆ¤æ–­æ˜¯å¦éœ€è¦ç­‰å¾…
        if !request.wait_for_completion {
            return Ok(ScrapeResponse::async_mode(task_id));
        }
        
        // 3. æ£€æŸ¥ç­‰å¾…é˜Ÿåˆ—å®¹é‡
        if !self.wait_manager.can_acquire().await {
            tracing::warn!("Wait queue full, fallback to async mode");
            return Ok(ScrapeResponse::async_mode(task_id));
        }
        
        // 4. æ³¨å†Œç­‰å¾…ç›‘å¬å™¨
        let wait_timeout = request.wait_timeout_ms
            .unwrap_or(self.config.default_wait_ms)
            .min(self.config.max_wait_ms);
        
        let receiver = self.wait_manager
            .register_waiter(task_id, wait_timeout)
            .await?;
        
        // 5. ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆå¸¦è¶…æ—¶ï¼‰
        match tokio::time::timeout(
            Duration::from_millis(wait_timeout),
            receiver.recv()
        ).await {
            Ok(Ok(result)) => {
                // ä»»åŠ¡åœ¨è¶…æ—¶å‰å®Œæˆ
                tracing::info!(
                    task_id = %task_id,
                    wait_time_ms = result.elapsed_ms,
                    "Task completed within wait timeout"
                );
                Ok(ScrapeResponse::immediate(result))
            }
            Ok(Err(_)) | Err(_) => {
                // è¶…æ—¶æˆ–é€šé“å…³é—­
                tracing::info!(
                    task_id = %task_id,
                    wait_timeout_ms = wait_timeout,
                    "Wait timeout, fallback to async mode"
                );
                Ok(ScrapeResponse::async_mode(task_id))
            }
        }
    }
}
```

**å…³é”®æŠ€æœ¯ç‚¹**:
1. **ä¿¡å·é‡æ§åˆ¶**: é™åˆ¶æœ€å¤§å¹¶å‘ç­‰å¾…æ•°ï¼ˆ500ï¼‰
2. **è¶…æ—¶ä¿æŠ¤**: ä½¿ç”¨ `tokio::time::timeout`
3. **é€šé“é€šçŸ¥**: Worker å®Œæˆä»»åŠ¡åé€šè¿‡ Channel é€šçŸ¥
4. **é™çº§ç­–ç•¥**: è¶…æ—¶åè‡ªåŠ¨è¿”å›å¼‚æ­¥å“åº”
```

---

### 2.2 ã€ç¬¬ 3 èŠ‚ - æ ¸å¿ƒæ¨¡å—è®¾è®¡ã€‘æ–°å¢ Wait Manager

**åœ¨ "3.5 å¹¶å‘æ§åˆ¶" ä¹‹åæ–°å¢ "3.6 ç­‰å¾…ç®¡ç†å™¨"**:

```markdown
### 3.6 ç­‰å¾…ç®¡ç†å™¨ï¼ˆWait Managerï¼‰ âœ¨ æ–°å¢

#### 3.6.1 æ¶æ„è®¾è®¡

```rust
// workers/wait_manager.rs
use tokio::sync::{mpsc, Semaphore};
use std::collections::HashMap;

pub struct WaitManager {
    // ç­‰å¾…ä¸­çš„ä»»åŠ¡æ˜ å°„ (task_id â†’ sender)
    waiters: Arc<RwLock<HashMap<Uuid, mpsc::Sender<TaskResult>>>>,
    
    // å¹¶å‘æ§åˆ¶ä¿¡å·é‡ï¼ˆæœ€å¤§ 500ï¼‰
    semaphore: Arc<Semaphore>,
    
    // Redis å®¢æˆ·ç«¯ï¼ˆç”¨äºè·¨è¿›ç¨‹é€šçŸ¥ï¼‰
    redis: ConnectionManager,
}

impl WaitManager {
    pub async fn new(redis: ConnectionManager) -> Self {
        Self {
            waiters: Arc::new(RwLock::new(HashMap::new())),
            semaphore: Arc::new(Semaphore::new(500)),
            redis,
        }
    }
    
    /// æ£€æŸ¥æ˜¯å¦å¯ä»¥è·å–ç­‰å¾…æ§½ä½
    pub async fn can_acquire(&self) -> bool {
        self.semaphore.available_permits() > 0
    }
    
    /// æ³¨å†Œç­‰å¾…ç›‘å¬å™¨
    pub async fn register_waiter(
        &self,
        task_id: Uuid,
        timeout_ms: u64,
    ) -> Result<mpsc::Receiver<TaskResult>, WaitError> {
        // è·å–ä¿¡å·é‡
        let _permit = self.semaphore
            .acquire()
            .await
            .map_err(|_| WaitError::QueueFull)?;
        
        // åˆ›å»ºé€šé“
        let (tx, rx) = mpsc::channel(1);
        
        // æ³¨å†Œåˆ°æ˜ å°„è¡¨
        self.waiters.write().await.insert(task_id, tx);
        
        // è®¾ç½®è¶…æ—¶æ¸…ç†
        let waiters = self.waiters.clone();
        tokio::spawn(async move {
            tokio::time::sleep(Duration::from_millis(timeout_ms)).await;
            waiters.write().await.remove(&task_id);
        });
        
        Ok(rx)
    }
    
    /// é€šçŸ¥ä»»åŠ¡å®Œæˆï¼ˆç”± Worker è°ƒç”¨ï¼‰
    pub async fn notify_completion(
        &self,
        task_id: Uuid,
        result: TaskResult,
    ) -> Result<(), WaitError> {
        // 1. æŸ¥æ‰¾æœ¬åœ°ç­‰å¾…è€…
        if let Some(tx) = self.waiters.write().await.remove(&task_id) {
            let _ = tx.send(result.clone()).await;
            return Ok(());
        }
        
        // 2. å¦‚æœæœ¬åœ°æ²¡æœ‰ï¼Œé€šè¿‡ Redis Pub/Sub é€šçŸ¥å…¶ä»–èŠ‚ç‚¹
        self.redis.publish(
            format!("task:completed:{}", task_id),
            serde_json::to_string(&result)?,
        ).await?;
        
        Ok(())
    }
    
    /// å¯åŠ¨ Redis è®¢é˜…ç›‘å¬å™¨ï¼ˆç”¨äºé›†ç¾¤æ¨¡å¼ï¼‰
    pub async fn start_subscription_listener(&self) {
        let mut pubsub = self.redis.get_async_pubsub().await.unwrap();
        pubsub.psubscribe("task:completed:*").await.unwrap();
        
        let waiters = self.waiters.clone();
        tokio::spawn(async move {
            while let Some(msg) = pubsub.on_message().next().await {
                let payload: String = msg.get_payload().unwrap();
                let result: TaskResult = serde_json::from_str(&payload).unwrap();
                
                // æå– task_id
                let channel = msg.get_channel_name();
                let task_id = Uuid::parse_str(
                    channel.strip_prefix("task:completed:").unwrap()
                ).unwrap();
                
                // é€šçŸ¥æœ¬åœ°ç­‰å¾…è€…
                if let Some(tx) = waiters.write().await.remove(&task_id) {
                    let _ = tx.send(result).await;
                }
            }
        });
    }
}
```

#### 3.6.2 ä¸ Worker çš„é›†æˆ

```rust
// workers/scrape_worker.rs
impl ScrapeWorker {
    async fn process_task(&self, task: Task) -> Result<(), WorkerError> {
        let task_id = task.id;
        
        // æ‰§è¡ŒæŠ“å–é€»è¾‘
        let result = match self.scrape_engine.execute(&task).await {
            Ok(data) => TaskResult::success(data),
            Err(e) => TaskResult::failure(e),
        };
        
        // æŒä¹…åŒ–ç»“æœåˆ°æ•°æ®åº“
        self.task_repo.save_result(task_id, &result).await?;
        
        // ğŸ”” é€šçŸ¥ç­‰å¾…ç®¡ç†å™¨ï¼ˆå…³é”®æ­¥éª¤ï¼‰
        self.wait_manager.notify_completion(task_id, result).await?;
        
        Ok(())
    }
}
```

#### 3.6.3 é…ç½®ç»“æ„

```rust
// config/settings.rs
#[derive(Debug, Clone, Deserialize)]
pub struct AsyncWaitConfig {
    /// ä¸åŒä»»åŠ¡ç±»å‹çš„é…ç½®
    pub scrape: TaskWaitConfig,
    pub search: TaskWaitConfig,
    pub extract: TaskWaitConfig,
    
    /// å…¨å±€é…ç½®
    pub max_concurrent_waiters: usize,  // é»˜è®¤ 500
}

#[derive(Debug, Clone, Deserialize)]
pub struct TaskWaitConfig {
    pub default_wait_ms: u64,
    pub max_wait_ms: u64,
}

impl Default for AsyncWaitConfig {
    fn default() -> Self {
        Self {
            scrape: TaskWaitConfig {
                default_wait_ms: 3000,
                max_wait_ms: 10000,
            },
            search: TaskWaitConfig {
                default_wait_ms: 2000,
                max_wait_ms: 5000,
            },
            extract: TaskWaitConfig {
                default_wait_ms: 5000,
                max_wait_ms: 15000,
            },
            max_concurrent_waiters: 500,
        }
    }
}
```
```

---

### 2.3 ã€ç¬¬ 6 èŠ‚ - ç›‘æ§ä¸å¯è§‚æµ‹æ€§ã€‘ä¿®æ­£

**åœ¨ "6.2 æŒ‡æ ‡é‡‡é›†ï¼ˆPrometheusï¼‰" ä¸‹æ–°å¢**:

```markdown
### 6.2 æŒ‡æ ‡é‡‡é›†ï¼ˆPrometheusï¼‰

```rust
// utils/metrics.rs
use prometheus::{Registry, Counter, Histogram, Gauge, opts};

lazy_static! {
    // åŸæœ‰æŒ‡æ ‡
    pub static ref TASK_CREATED: Counter = Counter::new(
        "crawlrs_tasks_created_total",
        "Total number of tasks created"
    ).unwrap();
    
    pub static ref SCRAPE_DURATION: Histogram = Histogram::with_opts(
        opts!(
            "crawlrs_scrape_duration_seconds",
            "Scrape request duration in seconds"
        ).buckets(vec![0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0])
    ).unwrap();
    
    // âœ¨ æ–°å¢ï¼šç­‰å¾…ç›¸å…³æŒ‡æ ‡
    pub static ref IMMEDIATE_RESPONSE_TOTAL: Counter = Counter::new(
        "crawlrs_immediate_response_total",
        "Total number of tasks completed within wait timeout"
    ).unwrap();
    
    pub static ref WAIT_TIMEOUT_TOTAL: Counter = Counter::new(
        "crawlrs_wait_timeout_total",
        "Total number of wait timeouts (fallback to async)"
    ).unwrap();
    
    pub static ref WAIT_DURATION: Histogram = Histogram::with_opts(
        opts!(
            "crawlrs_wait_duration_seconds",
            "Time spent waiting for task completion"
        ).buckets(vec![0.1, 0.5, 1.0, 2.0, 3.0, 5.0, 10.0, 15.0])
    ).unwrap();
    
    pub static ref WAIT_QUEUE_DEPTH: Gauge = Gauge::new(
        "crawlrs_wait_queue_depth",
        "Current number of requests waiting for task completion"
    ).unwrap();
    
    pub static ref IMMEDIATE_RESPONSE_RATIO: Gauge = Gauge::new(
        "crawlrs_immediate_response_ratio",
        "Ratio of immediate responses (target > 0.8)"
    ).unwrap();
}
```

**Grafana ä»ªè¡¨ç›˜æŸ¥è¯¢ç¤ºä¾‹**:
```promql
# ç«‹å³å“åº”ç‡ï¼ˆç›®æ ‡ > 80%ï¼‰
rate(crawlrs_immediate_response_total[5m]) 
/ 
(rate(crawlrs_immediate_response_total[5m]) + rate(crawlrs_wait_timeout_total[5m]))

# P95 ç­‰å¾…æ—¶é—´
histogram_quantile(0.95, rate(crawlrs_wait_duration_seconds_bucket[5m]))

# ç­‰å¾…é˜Ÿåˆ—æ·±åº¦è¶‹åŠ¿
crawlrs_wait_queue_depth
```
```

---

## 3. TASK.md ä¿®æ­£æ¸…å•

### 3.1 ã€Phase 2ã€‘æ–°å¢ä»»åŠ¡

**åœ¨ "Week 6: é˜Ÿåˆ—ä¸è°ƒåº¦" ä¹‹åæ’å…¥æ–°çš„ Week 6.5**:

```markdown
### 3.2.5 Week 6.5: å¼‚æ­¥ç­‰å¾…æœºåˆ¶å®ç° âœ¨ æ–°å¢

**TASK-013.5: Wait Manager å®ç°**
- **çŠ¶æ€**: â³ è®¡åˆ’ä¸­
- **ä¼˜å…ˆçº§**: P1
- **å·¥æ—¶**: 4 å¤©
- **è´Ÿè´£äºº**: åç«¯å·¥ç¨‹å¸ˆ
- **æè¿°**: å®ç°åŒæ­¥ç­‰å¾…ç®¡ç†å™¨å’Œè·¨è¿›ç¨‹é€šçŸ¥æœºåˆ¶
- **ä¾èµ–**: TASK-012 (ä»»åŠ¡é˜Ÿåˆ—å®ç°), TASK-013 (Worker ç®¡ç†å™¨)
- **åŠŸèƒ½è¦æ±‚**:
  - åŸºäº Tokio Channel çš„è¿›ç¨‹å†…é€šçŸ¥
  - åŸºäº Redis Pub/Sub çš„è·¨è¿›ç¨‹é€šçŸ¥
  - ä¿¡å·é‡æ§åˆ¶å¹¶å‘ç­‰å¾…æ•°ï¼ˆæœ€å¤§ 500ï¼‰
  - è¶…æ—¶è‡ªåŠ¨æ¸…ç†æœºåˆ¶
- **å…³é”®ä»£ç **:
  ```rust
  // workers/wait_manager.rs
  pub struct WaitManager {
      waiters: Arc<RwLock<HashMap<Uuid, mpsc::Sender<TaskResult>>>>,
      semaphore: Arc<Semaphore>,
      redis: ConnectionManager,
  }
  ```
- **éªŒæ”¶æ ‡å‡†**:
  - [ ] å•èŠ‚ç‚¹æ¨¡å¼ä¸‹é€šçŸ¥å»¶è¿Ÿ < 10ms
  - [ ] é›†ç¾¤æ¨¡å¼ä¸‹é€šçŸ¥å»¶è¿Ÿ < 50ms
  - [ ] ä¿¡å·é‡æ­£ç¡®é™åˆ¶å¹¶å‘æ•°
  - [ ] è¶…æ—¶åè‡ªåŠ¨æ¸…ç†ï¼Œæ— å†…å­˜æ³„æ¼
  - [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 90%

**TASK-013.6: API å±‚é›†æˆç­‰å¾…æœºåˆ¶**
- **çŠ¶æ€**: â³ è®¡åˆ’ä¸­
- **ä¼˜å…ˆçº§**: P1
- **å·¥æ—¶**: 3 å¤©
- **è´Ÿè´£äºº**: åç«¯å·¥ç¨‹å¸ˆ
- **æè¿°**: åœ¨ Scrape/Search/Extract æ¥å£ä¸­é›†æˆç­‰å¾…é€»è¾‘
- **ä¾èµ–**: TASK-013.5
- **åŠŸèƒ½è¦æ±‚**:
  - ä¿®æ”¹è¯·æ±‚ DTO æ·»åŠ  `wait_for_completion` å’Œ `wait_timeout_ms` å­—æ®µ
  - å®ç° `CreateScrapeWithWaitUseCase`
  - å“åº”ç»“æ„åŒºåˆ† `immediate` å’Œ `async` æ¨¡å¼
  - é…ç½®åŒ–çš„ç­‰å¾…æ—¶é—´ï¼ˆæŒ‰ä»»åŠ¡ç±»å‹ï¼‰
- **éªŒæ”¶æ ‡å‡†**:
  - [ ] å¿«é€Ÿä»»åŠ¡ï¼ˆ< 2sï¼‰ç«‹å³è¿”å›ç‡ > 90%
  - [ ] è¶…æ—¶ä»»åŠ¡æ­£ç¡®é™çº§ä¸ºå¼‚æ­¥æ¨¡å¼
  - [ ] ä¸å½±å“åŸæœ‰å¼‚æ­¥æ¥å£æ€§èƒ½
  - [ ] é›†æˆæµ‹è¯•é€šè¿‡

**TASK-013.7: ç›‘æ§æŒ‡æ ‡å®ç°**
- **çŠ¶æ€**: â³ è®¡åˆ’ä¸­
- **ä¼˜å…ˆçº§**: P2
- **å·¥æ—¶**: 2 å¤©
- **è´Ÿè´£äºº**: DevOps
- **æè¿°**: æ·»åŠ ç­‰å¾…æœºåˆ¶ç›¸å…³çš„ Prometheus æŒ‡æ ‡
- **ä¾èµ–**: TASK-013.6
- **åŠŸèƒ½è¦æ±‚**:
  - å®ç° `IMMEDIATE_RESPONSE_TOTAL` è®¡æ•°å™¨
  - å®ç° `WAIT_TIMEOUT_TOTAL` è®¡æ•°å™¨
  - å®ç° `WAIT_DURATION` ç›´æ–¹å›¾
  - å®ç° `WAIT_QUEUE_DEPTH` ä»ªè¡¨
  - é…ç½® Grafana ä»ªè¡¨ç›˜
- **éªŒæ”¶æ ‡å‡†**:
  - [ ] æ‰€æœ‰æŒ‡æ ‡æ­£ç¡®é‡‡é›†
  - [ ] Grafana é¢æ¿æ­£å¸¸æ˜¾ç¤º
  - [ ] å‘Šè­¦è§„åˆ™é…ç½®å®Œæˆï¼ˆç«‹å³å“åº”ç‡ < 70% æ—¶å‘Šè­¦ï¼‰
```

---

### 3.2 ã€Phase 3ã€‘æ–°å¢æ€§èƒ½æµ‹è¯•ä»»åŠ¡

**åœ¨ "Week 10: æ€§èƒ½ä¼˜åŒ–" ä¸‹æ–°å¢ TASK-021.5**:

```markdown
**TASK-021.5: ç­‰å¾…æœºåˆ¶æ€§èƒ½æµ‹è¯•**
- **çŠ¶æ€**: â³ è®¡åˆ’ä¸­
- **ä¼˜å…ˆçº§**: P1
- **å·¥æ—¶**: 2 å¤©
- **è´Ÿè´£äºº**: QA
- **æè¿°**: éªŒè¯ç­‰å¾…æœºåˆ¶åœ¨é«˜å¹¶å‘ä¸‹çš„æ€§èƒ½è¡¨ç°
- **ä¾èµ–**: TASK-013.6, TASK-013.7
- **æµ‹è¯•åœºæ™¯**:
  1. **åœºæ™¯ 1: çº¯åŒæ­¥æ¨¡å¼**
     - 100 VUï¼Œ100% è¯·æ±‚å¯ç”¨ wait_for_completion
     - éªŒè¯çº¿ç¨‹æ± ä¸è¢«é˜»å¡
  2. **åœºæ™¯ 2: æ··åˆæ¨¡å¼**
     - 500 VUï¼Œ70% åŒæ­¥ + 30% å¼‚æ­¥
     - éªŒè¯ä¸¤ç§æ¨¡å¼äº’ä¸å½±å“
  3. **åœºæ™¯ 3: ä¿¡å·é‡è€—å°½**
     - 600 å¹¶å‘ç­‰å¾…è¯·æ±‚ï¼ˆè¶…è¿‡ 500 é™åˆ¶ï¼‰
     - éªŒè¯é™çº§é€»è¾‘
- **éªŒæ”¶æ ‡å‡†**:
  - [ ] åŒæ­¥æ¨¡å¼ P95 å»¶è¿Ÿ < 5s
  - [ ] å¼‚æ­¥æ¨¡å¼ P95 å»¶è¿Ÿ < 200msï¼ˆä¸å—å½±å“ï¼‰
  - [ ] ä¿¡å·é‡è€—å°½æ—¶æ­£ç¡®é™çº§ï¼Œæ— è¯·æ±‚å¤±è´¥
  - [ ] ç«‹å³å“åº”ç‡ > 80%
  - [ ] æ— å†…å­˜æ³„æ¼

---

### 3.3 ã€å·¥æ—¶é¢„ä¼°ã€‘æ›´æ–°

**ä¿®æ­£ "7.2 å·¥æ—¶é¢„ä¼°è¡¨"**:

```markdown
| Phase | äººå¤© | å…³é”®è·¯å¾„ |
|-------|------|----------|
| Phase 1 | 45 | æ•°æ®åº“è®¾è®¡ â†’ ä»“å‚¨å®ç° â†’ API å±‚ |
| Phase 2 | 69 | æŠ“å–å¼•æ“ â†’ é˜Ÿåˆ—ç³»ç»Ÿ â†’ **ç­‰å¾…æœºåˆ¶** â†’ çˆ¬å–é€»è¾‘ | âœ¨ å·¥æ—¶ +9 å¤©
| Phase 3 | 32 | Webhook â†’ ç›‘æ§ â†’ ä¼˜åŒ– â†’ **ç­‰å¾…æ€§èƒ½æµ‹è¯•** | âœ¨ å·¥æ—¶ +2 å¤©
| Phase 4 | 25 | æµ‹è¯• â†’ éƒ¨ç½² â†’ æ–‡æ¡£ |
| **æ€»è®¡** | **171** | **çº¦ 12.5 å‘¨** | âœ¨ å»¶é•¿ 0.5 å‘¨
```

---

## 4. TEST.md ä¿®æ­£æ¸…å•

### 4.1 ã€ç¬¬ 2 èŠ‚ - å•å…ƒæµ‹è¯•ã€‘æ–°å¢æµ‹è¯•ç”¨ä¾‹

**åœ¨ "2.3 å¹¶å‘æ§åˆ¶æµ‹è¯•" ä¹‹åæ–°å¢ "2.4 ç­‰å¾…ç®¡ç†å™¨æµ‹è¯•"**:

```markdown
### 2.4 ç­‰å¾…ç®¡ç†å™¨æµ‹è¯• âœ¨ æ–°å¢

#### æµ‹è¯•ç”¨ä¾‹ï¼šæ³¨å†Œä¸é€šçŸ¥

```rust
// tests/unit/workers/wait_manager_test.rs
use crawlrs::workers::WaitManager;

#[tokio::test]
async fn test_register_and_notify_completion() {
    // Given: Wait Manager
    let redis = setup_test_redis().await;
    let wait_manager = WaitManager::new(redis);
    
    let task_id = Uuid::new_v4();
    
    // When: æ³¨å†Œç­‰å¾…ç›‘å¬å™¨
    let receiver = wait_manager
        .register_waiter(task_id, 5000)
        .await
        .unwrap();
    
    // æ¨¡æ‹Ÿ Worker å®Œæˆä»»åŠ¡
    let result = TaskResult::success("test data");
    wait_manager.notify_completion(task_id, result.clone()).await.unwrap();
    
    // Then: ç›‘å¬å™¨åº”æ”¶åˆ°ç»“æœ
    let received = receiver.recv().await.unwrap();
    assert_eq!(received.data, "test data");
}

#[tokio::test]
async fn test_wait_timeout() {
    let redis = setup_test_redis().await;
    let wait_manager = WaitManager::new(redis);
    
    let task_id = Uuid::new_v4();
    
    // When: æ³¨å†Œ 100ms è¶…æ—¶
    let receiver = wait_manager
        .register_waiter(task_id, 100)
        .await
        .unwrap();
    
    // Then: 100ms ååº”è¶…æ—¶
    let result = tokio::time::timeout(
        Duration::from_millis(150),
        receiver.recv()
    ).await;
    
    assert!(result.is_err(), "Should timeout");
}

#[tokio::test]
async fn test_semaphore_limit() {
    let redis = setup_test_redis().await;
    let wait_manager = WaitManager::new(redis);
    
    // Given: ä¿¡å·é‡å®¹é‡ä¸º 500
    let mut receivers = Vec::new();
    
    // When: æ³¨å†Œ 500 ä¸ªç­‰å¾…è€…
    for _ in 0..500 {
        let task_id = Uuid::new_v4();
        let rx = wait_manager
            .register_waiter(task_id, 10000)
            .await
            .unwrap();
        receivers.push(rx);
    }
    
    // Then: ç¬¬ 501 ä¸ªåº”æ— æ³•è·å–æ§½ä½
    assert!(!wait_manager.can_acquire().await);
    
    // When: é‡Šæ”¾ä¸€ä¸ªæ§½ä½
    drop(receivers.pop());
    tokio::time::sleep(Duration::from_millis(50)).await;
    
    // Then: åº”è¯¥å¯ä»¥å†æ¬¡è·å–
    assert!(wait_manager.can_acquire().await);
}
```

**æµ‹è¯•è¦†ç›–**:
- âœ… æˆåŠŸæ³¨å†Œå’Œé€šçŸ¥
- âœ… è¶…æ—¶è‡ªåŠ¨æ¸…ç†
- âœ… ä¿¡å·é‡é™åˆ¶ç”Ÿæ•ˆ
- âœ… è·¨è¿›ç¨‹é€šçŸ¥ï¼ˆRedis Pub/Subï¼‰
```

---

### 4.2 ã€ç¬¬ 3 èŠ‚ - é›†æˆæµ‹è¯•ã€‘æ–°å¢æµ‹è¯•åœºæ™¯

**åœ¨ "3.1 API ç«¯åˆ°ç«¯æµ‹è¯•" ä¸‹æ–°å¢åœºæ™¯**:

```markdown
#### æµ‹è¯•ç”¨ä¾‹ï¼šåŒæ­¥ç­‰å¾…æ¨¡å¼ âœ¨ æ–°å¢

```rust
// tests/integration/api/scrape_wait_test.rs
use axum_test::TestServer;

#[tokio::test]
async fn test_scrape_with_immediate_response() {
    // Given: æµ‹è¯•æœåŠ¡å™¨
    let app = create_test_app().await;
    let server = TestServer::new(app).unwrap();
    
    // When: POST /v1/scrapeï¼ˆå¯ç”¨åŒæ­¥ç­‰å¾…ï¼‰
    let start = Instant::now();
    let response = server
        .post("/v1/scrape")
        .json(&json!({
            "url": "https://example.com",
            "formats": ["markdown"],
            "options": {
                "wait_for_completion": true,
                "wait_timeout_ms": 5000
            }
        }))
        .add_header("Authorization", "Bearer test-api-key")
        .await;
    
    let elapsed = start.elapsed();
    
    // Then: åº”åœ¨ 5 ç§’å†…è¿”å›å®Œæ•´ç»“æœ
    response.assert_status_ok();
    let body: ScrapeResponse = response.json();
    
    assert_eq!(body.mode, "immediate");
    assert!(body.data.is_some());
    assert!(elapsed < Duration::from_secs(5));
}

#[tokio::test]
async fn test_scrape_wait_timeout_fallback() {
    let app = create_test_app().await;
    let server = TestServer::new(app).unwrap();
    
    // When: æŠ“å–æ…¢é€Ÿç«™ç‚¹ï¼ˆ10 ç§’å“åº”ï¼‰ï¼Œä½†åªç­‰å¾… 2 ç§’
    let response = server
        .post("/v1/scrape")
        .json(&json!({
            "url": "https://slow-site.example.com",  // æ¨¡æ‹Ÿæ…¢é€Ÿç«™ç‚¹
            "options": {
                "wait_for_completion": true,
                "wait_timeout_ms": 2000
            }
        }))
        .await;
    
    // Then: åº”åœ¨ 2 ç§’åè¿”å›å¼‚æ­¥å“åº”
    response.assert_status_ok();
    let body: ScrapeResponse = response.json();
    
    assert_eq!(body.mode, "async");
    assert!(body.id.is_some());
    assert!(body.data.is_none());
}

#[tokio::test]
async fn test_wait_semaphore_exhaustion() {
    let app = create_test_app().await;
    let server = TestServer::new(app).unwrap();
    
    // When: å¹¶å‘å‘é€ 501 ä¸ªç­‰å¾…è¯·æ±‚ï¼ˆè¶…è¿‡ 500 é™åˆ¶ï¼‰
    let handles: Vec<_> = (0..501)
        .map(|i| {
            let server = server.clone();
            tokio::spawn(async move {
                server
                    .post("/v1/scrape")
                    .json(&json!({
                        "url": format!("https://example.com/page{}", i),
                        "options": {
                            "wait_for_completion": true,
                            "wait_timeout_ms": 10000
                        }
                    }))
                    .await
            })
        })
        .collect();
    
    let results = futures::future::join_all(handles).await;
    
    // Then: è‡³å°‘æœ‰ 1 ä¸ªè¯·æ±‚é™çº§ä¸ºå¼‚æ­¥æ¨¡å¼
    let async_count = results
        .into_iter()
        .filter(|r| {
            let body: ScrapeResponse = r.as_ref().unwrap().json();
            body.mode == "async"
        })
        .count();
    
    assert!(async_count > 0, "Should have at least 1 fallback to async");
}
```

**æµ‹è¯•è¦†ç›–**:
- âœ… å¿«é€Ÿä»»åŠ¡ç«‹å³è¿”å›
- âœ… è¶…æ—¶ä»»åŠ¡é™çº§ä¸ºå¼‚æ­¥
- âœ… ä¿¡å·é‡è€—å°½æ—¶çš„é™çº§
- âœ… å®¢æˆ·ç«¯è¶…æ—¶å¤„ç†
```

---

### 4.3 ã€ç¬¬ 4 èŠ‚ - å‹åŠ›æµ‹è¯•ã€‘æ–°å¢åœºæ™¯

**åœ¨ "4.1 æµ‹è¯•åœºæ™¯" ä¸‹æ–°å¢åœºæ™¯ 4**:

```markdown
#### åœºæ™¯ 4: æ··åˆåŒæ­¥/å¼‚æ­¥æ¨¡å¼ âœ¨ æ–°å¢

**ç›®æ ‡**: éªŒè¯åŒæ­¥ç­‰å¾…ä¸å½±å“å¼‚æ­¥æ¥å£æ€§èƒ½

**æµ‹è¯•è„šæœ¬** (k6):
```javascript
// tests/load/mixed_mode.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  scenarios: {
    // 70% ç”¨æˆ·ä½¿ç”¨åŒæ­¥ç­‰å¾…æ¨¡å¼
    sync_mode: {
      executor: 'constant-vus',
      vus: 350,
      duration: '5m',
      exec: 'syncRequest',
    },
    // 30% ç”¨æˆ·ä½¿ç”¨çº¯å¼‚æ­¥æ¨¡å¼
    async_mode: {
      executor: 'constant-vus',
      vus: 150,
      duration: '5m',
      exec: 'asyncRequest',
    },
  },
  thresholds: {
    'http_req_duration{mode:sync}': ['p(95)<5000'],   // åŒæ­¥æ¨¡å¼ P95 < 5s
    'http_req_duration{mode:async}': ['p(95)<200'],   // å¼‚æ­¥æ¨¡å¼ P95 < 200ms
    'immediate_response_rate': ['value>0.8'],         // ç«‹å³å“åº”ç‡ > 80%
  },
};

export function syncRequest() {
  const payload = JSON.stringify({
    url: 'https://example.com',
    formats: ['markdown'],
    options: {
      wait_for_completion: true,
      wait_timeout_ms: 5000,
    },
  });
  
  const res = http.post('http://localhost:8080/v1/scrape', payload, {
    headers: { 'Content-Type': 'application/json', 'Authorization': 'Bearer test-key' },
    tags: { mode: 'sync' },
  });
  
  check(res, {
    'status is 200': (r) => r.status === 200,
    'is immediate response': (r) => JSON.parse(r.body).mode === 'immediate',
  });
  
  sleep(1);
}

export function asyncRequest() {
  const payload = JSON.stringify({
    url: 'https://example.com',
    formats: ['markdown'],
    options: {
      wait_for_completion: false,  // çº¯å¼‚æ­¥
    },
  });
  
  const res = http.post('http://localhost:8080/v1/scrape', payload, {
    headers: { 'Content-Type': 'application/json', 'Authorization': 'Bearer test-key' },
    tags: { mode: 'async' },
  });
  
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 200ms': (r) => r.timings.duration < 200,
  });
  
  sleep(1);
}
```

**é¢„æœŸç»“æœ**:
- âœ… åŒæ­¥æ¨¡å¼ P95 å»¶è¿Ÿ < 5s
- âœ… å¼‚æ­¥æ¨¡å¼ P95 å»¶è¿Ÿ < 200msï¼ˆä¸å—å½±å“ï¼‰
- âœ… ç«‹å³å“åº”ç‡ > 80%
- âœ… æ— å†…å­˜æ³„æ¼
- âœ… ä¿¡å·é‡æ­£ç¡®é™åˆ¶å¹¶å‘æ•°
```

---

## 5. UAT.md ä¿®æ­£æ¸…å•

### 5.1 ã€ç¬¬ 2 èŠ‚ - åŠŸèƒ½éªŒæ”¶æµ‹è¯•ã€‘æ–°å¢æµ‹è¯•ç”¨ä¾‹

**åœ¨ "2.2 æŠ“å–åŠŸèƒ½ï¼ˆScrapeï¼‰" ä¸‹æ–°å¢ UAT-005.5**:

```markdown
#### UAT-005.5: åŒæ­¥ç­‰å¾…æ¨¡å¼ âœ¨ æ–°å¢
**æµ‹è¯•åœºæ™¯**: å¯ç”¨åŒæ­¥ç­‰å¾…ï¼Œå¿«é€Ÿä»»åŠ¡ç«‹å³è¿”å›ç»“æœ

**æµ‹è¯•æ­¥éª¤**:
1. POST /v1/scrape
   ```json
   {
     "url": "https://example.com",
     "formats": ["markdown"],
     "options": {
       "wait_for_completion": true,
       "wait_timeout_ms": 5000
     }
   }
   ```
2. è®°å½•å“åº”æ—¶é—´
3. éªŒè¯å“åº”ç»“æ„

**é¢„æœŸç»“æœ**:
- å“åº”æ—¶é—´ < 5 ç§’
- å“åº”åŒ…å« `mode: "immediate"`
- å“åº”åŒ…å«å®Œæ•´çš„ `data` å­—æ®µ
- æ— éœ€è½®è¯¢æŸ¥è¯¢

**å®é™…ç»“æœ**: 
- [ ] é€šè¿‡ / [ ] å¤±è´¥
- **å“åº”æ—¶é—´**: _____ ms
- **å¤‡æ³¨**: _______________

---

#### UAT-005.6: ç­‰å¾…è¶…æ—¶é™çº§ âœ¨ æ–°å¢
**æµ‹è¯•åœºæ™¯**: ä»»åŠ¡è¶…æ—¶åè‡ªåŠ¨é™çº§ä¸ºå¼‚æ­¥æ¨¡å¼

**æµ‹è¯•æ­¥éª¤**:
1. POST /v1/scrapeï¼ˆæŠ“å–æ…¢é€Ÿç«™ç‚¹ï¼‰
   ```json
   {
     "url": "https://very-slow-site.com",
     "options": {
       "wait_for_completion": true,
       "wait_timeout_ms": 2000
     }
   }
   ```
2. ç­‰å¾… 2 ç§’
3. éªŒè¯å“åº”ç±»å‹

**é¢„æœŸç»“æœ**:
- 2 ç§’åè¿”å›å“åº”
- å“åº”åŒ…å« `mode: "async"`
- å“åº”åŒ…å«ä»»åŠ¡ ID
- ä»»åŠ¡ç»§ç»­åœ¨åå°æ‰§è¡Œ
- åç»­å¯é€šè¿‡ GET /v1/scrape/:id æŸ¥è¯¢ç»“æœ

**å®é™…ç»“æœ**: 
- [ ] é€šè¿‡ / [ ] å¤±è´¥
- **å¤‡æ³¨**: _______________

---

#### UAT-005.7: ä¿¡å·é‡é™åˆ¶ âœ¨ æ–°å¢
**æµ‹è¯•åœºæ™¯**: éªŒè¯å¹¶å‘ç­‰å¾…æ•°é‡é™åˆ¶

**æµ‹è¯•æ­¥éª¤**:
1. å¹¶å‘å‘é€ 501 ä¸ªç­‰å¾…è¯·æ±‚
2. è§‚å¯Ÿç¬¬ 501 ä¸ªè¯·æ±‚çš„å“åº”

**é¢„æœŸç»“æœ**:
- å‰ 500 ä¸ªè¯·æ±‚æ­£å¸¸ç­‰å¾…
- ç¬¬ 501 ä¸ªè¯·æ±‚ç«‹å³è¿”å› `mode: "async"`
- æ—¥å¿—åŒ…å« "Wait queue full" è­¦å‘Š
- æ— è¯·æ±‚å¤±è´¥

**å®é™…ç»“æœ**: 
- [ ] é€šè¿‡ / [ ] å¤±è´¥
- **å¤‡æ³¨**: _______________
```

---

### 5.2 ã€ç¬¬ 6 èŠ‚ - æ€§èƒ½éªŒæ”¶æµ‹è¯•ã€‘æ–°å¢æŒ‡æ ‡

**åœ¨ "6.1 ååé‡æµ‹è¯•" ä¸‹æ–°å¢ UAT-018.5**:

```markdown
#### UAT-018.5: æ··åˆæ¨¡å¼æ€§èƒ½ âœ¨ æ–°å¢
**æµ‹è¯•åœºæ™¯**: åŒæ­¥/å¼‚æ­¥æ··åˆè´Ÿè½½

**æµ‹è¯•å·¥å…·**: K6

**æµ‹è¯•è„šæœ¬**: `tests/load/mixed_mode.js`ï¼ˆè§ TEST.mdï¼‰

**é¢„æœŸç»“æœ**:
- åŒæ­¥æ¨¡å¼ P95 å»¶è¿Ÿ < 5000ms
- å¼‚æ­¥æ¨¡å¼ P95 å»¶è¿Ÿ < 200ms
- ç«‹å³å“åº”ç‡ > 80%
- ä¸¤ç§æ¨¡å¼äº’ä¸å½±å“

**å®é™…ç»“æœ**: 
- åŒæ­¥æ¨¡å¼ P95: _____ ms
- å¼‚æ­¥æ¨¡å¼ P95: _____ ms
- ç«‹å³å“åº”ç‡: _____ %
- [ ] é€šè¿‡ / [ ] å¤±è´¥
```

---

### 5.3 ã€ç¬¬ 8 èŠ‚ - ç›‘æ§éªŒæ”¶æµ‹è¯•ã€‘æ–°å¢æŒ‡æ ‡éªŒè¯

**åœ¨ "8.2 æŒ‡æ ‡" ä¸‹æ–°å¢ UAT-025.5**:

```markdown
#### UAT-025.5: ç­‰å¾…æœºåˆ¶æŒ‡æ ‡ âœ¨ æ–°å¢
**æµ‹è¯•åœºæ™¯**: éªŒè¯ç­‰å¾…ç›¸å…³æŒ‡æ ‡é‡‡é›†

**æµ‹è¯•æ­¥éª¤**:
1. è®¿é—® /metrics ç«¯ç‚¹
2. åœ¨ Prometheus ä¸­æŸ¥è¯¢æŒ‡æ ‡
3. åœ¨ Grafana ä¸­æŸ¥çœ‹é¢æ¿

**é¢„æœŸç»“æœ**:
- `crawlrs_immediate_response_total` æ­£ç¡®è®¡æ•°
- `crawlrs_wait_timeout_total` æ­£ç¡®è®¡æ•°
- `crawlrs_wait_duration_seconds` ç›´æ–¹å›¾æ­£ç¡®åˆ†æ¡¶
- `crawlrs_wait_queue_depth` å®æ—¶æ›´æ–°
- `crawlrs_immediate_response_ratio` è®¡ç®—æ­£ç¡®ï¼ˆ> 0.8ï¼‰

**å®é™…ç»“æœ**: 
- [ ] é€šè¿‡ / [ ] å¤±è´¥
- **ç«‹å³å“åº”ç‡**: _____ %
- **å¤‡æ³¨**: _______________
```

---

### 5.4 ã€ç¬¬ 12 èŠ‚ - éªŒæ”¶æ€»ç»“ã€‘æ›´æ–°ç»Ÿè®¡è¡¨

**ä¿®æ­£ "12.1 æµ‹è¯•ç»Ÿè®¡è¡¨"**:

```markdown
| ç±»åˆ« | æ€»æ•° | é€šè¿‡ | å¤±è´¥ | é€šè¿‡ç‡ |
|------|------|------|------|--------|
| åŠŸèƒ½æµ‹è¯• | 18 | ___ | ___ | ___% | âœ¨ æ€»æ•° +3
| å¹¶å‘æµ‹è¯• | 2 | ___ | ___ | ___% |
| é”™è¯¯å¤„ç† | 3 | ___ | ___ | ___% |
| Webhook | 2 | ___ | ___ | ___% |
| æ€§èƒ½æµ‹è¯• | 4 | ___ | ___ | ___% | âœ¨ æ€»æ•° +1
| éƒ¨ç½²æµ‹è¯• | 3 | ___ | ___ | ___% |
| ç›‘æ§æµ‹è¯• | 4 | ___ | ___ | ___% | âœ¨ æ€»æ•° +1
| ç¨³å®šæ€§æµ‹è¯• | 1 | ___ | ___ | ___% |
| å®‰å…¨æµ‹è¯• | 2 | ___ | ___ | ___% |
| æ–‡æ¡£éªŒæ”¶ | 2 | ___ | ___ | ___% |
| **æ€»è®¡** | **41** | ___ | ___ | ___% | âœ¨ æ€»æ•° +5
```

---

## 6. é€šç”¨ä¿®æ­£è¯´æ˜

### 6.1 API ç‰ˆæœ¬ç­–ç•¥

**æ‰€æœ‰æ–‡æ¡£ä¸­æ¶‰åŠ API ç«¯ç‚¹çš„åœ°æ–¹ï¼Œæ·»åŠ ç‰ˆæœ¬è¯´æ˜**:

```markdown
### API ç‰ˆæœ¬å…¼å®¹æ€§

#### v1.0ï¼ˆå½“å‰ï¼‰
- é»˜è®¤è¡Œä¸ºï¼šå¼‚æ­¥è¿”å›ä»»åŠ¡ ID
- æ‰€æœ‰ç°æœ‰å®¢æˆ·ç«¯æ— éœ€ä¿®æ”¹

#### v1.1ï¼ˆæ–°å¢ï¼Œæ¨èï¼‰âœ¨
- æ–°å¢å‚æ•°ï¼š`wait_for_completion`ã€`wait_timeout_ms`
- å‘åå…¼å®¹ v1.0
- è¯·æ±‚ç¤ºä¾‹ï¼š
  ```http
  POST /v1/scrape?api_version=1.1
  ```

#### è¿ç§»æ—¶é—´è¡¨
- **2024-12-18**: v1.1 å‘å¸ƒï¼Œv1.0 æ ‡è®°ä¸º Deprecated
- **2025-03-18**: v1.0 åœæ­¢æ”¯æŒï¼ˆ3 ä¸ªæœˆè¿‡æ¸¡æœŸï¼‰
- **2025-03-19**: v1.0 è¿”å› 410 Gone
```

---

### 6.2 é…ç½®æ–‡ä»¶ç¤ºä¾‹

**æ‰€æœ‰æ–‡æ¡£ä¸­æ·»åŠ é…ç½®ç¤ºä¾‹**:

```toml
# config/production.toml

[async_wait]
max_concurrent_waiters = 500

[async_wait.scrape]
default_wait_ms = 3000
max_wait_ms = 10000

[async_wait.search]
default_wait_ms = 2000
max_wait_ms = 5000

[async_wait.extract]
default_wait_ms = 5000
max_wait_ms = 15000
```

---

### 6.3 é”™è¯¯ç æ–°å¢

**åœ¨æ‰€æœ‰æ–‡æ¡£çš„é”™è¯¯ç ç« èŠ‚æ·»åŠ **:

```markdown
| é”™è¯¯ç  | HTTP çŠ¶æ€ | è¯´æ˜ | åœºæ™¯ |
|-------|----------|------|------|
| `WAIT_QUEUE_FULL` | 503 | ç­‰å¾…é˜Ÿåˆ—å·²æ»¡ | å¹¶å‘ç­‰å¾…æ•° > 500 | âœ¨ æ–°å¢
| `WAIT_TIMEOUT_EXCEEDED` | 200 | ç­‰å¾…è¶…æ—¶ï¼ˆé™çº§ä¸ºå¼‚æ­¥ï¼‰ | ä»»åŠ¡æœªåœ¨ wait_timeout_ms å†…å®Œæˆ | âœ¨ æ–°å¢
```

---

## 7. æ–‡æ¡£ä¿®è®¢ç‰ˆæœ¬å·æ›´æ–°

**æ‰€æœ‰ 5 ä¸ªæ–‡æ¡£çš„ç‰ˆæœ¬ä¿¡æ¯ç»Ÿä¸€æ›´æ–°ä¸º**:

```markdown
## ç‰ˆæœ¬ä¿¡æ¯
- **æ–‡æ¡£ç‰ˆæœ¬**: v2.1.0 âœ¨
- **å˜æ›´ç±»å‹**: åŠŸèƒ½å¢å¼º - å¼‚æ­¥æ¥å£åŒæ­¥ç­‰å¾…ä¼˜åŒ–
- **å˜æ›´æ—¥æœŸ**: 2024-12-18
- **å‘åå…¼å®¹**: âœ… æ˜¯ï¼ˆé»˜è®¤è¡Œä¸ºä¸å˜ï¼‰
```

---

## 8. å˜æ›´è®°å½•è¿½åŠ 

**æ‰€æœ‰æ–‡æ¡£çš„å˜æ›´è®°å½•è¡¨æ ¼æœ«å°¾æ·»åŠ **:

```markdown
| ç‰ˆæœ¬ | æ—¥æœŸ | å˜æ›´å†…å®¹ | ä½œè€… |
|------|------|---------|------|
| v2.1.0 | 2024-12-18 | æ–°å¢å¼‚æ­¥æ¥å£åŒæ­¥ç­‰å¾…æœºåˆ¶ | æŠ€æœ¯å›¢é˜Ÿ | âœ¨
| v2.0.0 | 2024-12-10 | Rust é‡æ„åˆå§‹ç‰ˆæœ¬ | æ¶æ„å›¢é˜Ÿ |
```

---

## 9. å®æ–½æ£€æŸ¥æ¸…å•

### 9.1 PRD.md
- [ ] ç¬¬ 3.1 èŠ‚ï¼šSearch è¾“å…¥/è¾“å‡ºä¿®æ­£
- [ ] ç¬¬ 3.2 èŠ‚ï¼šScrape è¾“å…¥/è¾“å‡ºä¿®æ­£
- [ ] ç¬¬ 3.4 èŠ‚ï¼šExtract è¾“å…¥ä¿®æ­£
- [ ] æ–°å¢ç¬¬ 3.6 èŠ‚ï¼šå¼‚æ­¥ç­‰å¾…æœºåˆ¶
- [ ] ç¬¬ 8.1 èŠ‚ï¼šæ€§èƒ½æŒ‡æ ‡æ–°å¢
- [ ] ç¬¬ 10.1 èŠ‚ï¼šç›‘æ§æŒ‡æ ‡æ–°å¢
- [ ] ç‰ˆæœ¬å·æ›´æ–°ä¸º v2.1.0
- [ ] å˜æ›´è®°å½•è¿½åŠ 

### 9.2 TDD.md
- [ ] ç¬¬ 3.2.2 èŠ‚ï¼šæ–°å¢ CreateScrapeWithWaitUseCase
- [ ] ç¬¬ 3.6 èŠ‚ï¼šæ–°å¢ Wait Manager è®¾è®¡
- [ ] ç¬¬ 6.2 èŠ‚ï¼šæ–°å¢ç­‰å¾…ç›¸å…³æŒ‡æ ‡
- [ ] ç‰ˆæœ¬å·æ›´æ–°ä¸º v2.1.0
- [ ] å˜æ›´è®°å½•è¿½åŠ 

### 9.3 TASK.md
- [ ] Phase 2 æ–°å¢ Week 6.5
- [ ] æ–°å¢ TASK-013.5: Wait Manager å®ç°
- [ ] æ–°å¢ TASK-013.6: API å±‚é›†æˆ
- [ ] æ–°å¢ TASK-013.7: ç›‘æ§æŒ‡æ ‡å®ç°
- [ ] Phase 3 æ–°å¢ TASK-021.5: æ€§èƒ½æµ‹è¯•
- [ ] å·¥æ—¶é¢„ä¼°è¡¨æ›´æ–°ï¼ˆ+11 å¤©ï¼‰
- [ ] ç‰ˆæœ¬å·æ›´æ–°ä¸º v2.1.0
- [ ] å˜æ›´è®°å½•è¿½åŠ 

### 9.4 TEST.md
- [ ] ç¬¬ 2.4 èŠ‚ï¼šæ–°å¢ç­‰å¾…ç®¡ç†å™¨å•å…ƒæµ‹è¯•
- [ ] ç¬¬ 3.1 èŠ‚ï¼šæ–°å¢åŒæ­¥ç­‰å¾…é›†æˆæµ‹è¯•
- [ ] ç¬¬ 4.1 èŠ‚ï¼šæ–°å¢æ··åˆæ¨¡å¼å‹åŠ›æµ‹è¯•
- [ ] ç‰ˆæœ¬å·æ›´æ–°ä¸º v2.1.0
- [ ] å˜æ›´è®°å½•è¿½åŠ 

### 9.5 UAT.md
- [ ] ç¬¬ 2.2 èŠ‚ï¼šæ–°å¢ UAT-005.5/005.6/005.7
- [ ] ç¬¬ 6.1 èŠ‚ï¼šæ–°å¢ UAT-018.5
- [ ] ç¬¬ 8.2 èŠ‚ï¼šæ–°å¢ UAT-025.5
- [ ] ç¬¬ 12.1 èŠ‚ï¼šæµ‹è¯•ç»Ÿè®¡è¡¨æ›´æ–°
- [ ] ç‰ˆæœ¬å·æ›´æ–°ä¸º v2.1.0
- [ ] å˜æ›´è®°å½•è¿½åŠ 

---

## 10. å®¡é˜…ä¸æ‰¹å‡†

### å®¡é˜…äººå‘˜
- [ ] æŠ€æœ¯è´Ÿè´£äºº
- [ ] äº§å“ç»ç†
- [ ] QA è´Ÿè´£äºº
- [ ] DevOps å·¥ç¨‹å¸ˆ

### æ‰¹å‡†çŠ¶æ€
- **æ‰¹å‡†æ—¥æœŸ**: _______________
- **ç”Ÿæ•ˆæ—¥æœŸ**: _______________

---

**æ–‡æ¡£çŠ¶æ€**: ğŸš§ å¾…å®¡é˜…
**ä¼˜å…ˆçº§**: P1ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
**é¢„è®¡å®æ–½æ—¶é—´**: Phase 2 - Week 6.5ï¼ˆçº¦ç¬¬ 7 å‘¨ï¼‰